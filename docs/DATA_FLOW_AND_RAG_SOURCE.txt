================================================================================
COMPLETE DATA FLOW AND RAG DATASET SOURCE
================================================================================

ğŸ“Š DATASET SOURCES (Where RAG gets data)
================================================================================

  OPTION 1: Manual Seeding
  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  â””â”€ scripts/seed_rag.py
     â””â”€ Hard-coded examples:
        â€¢ 3 anomalous: SQL Injection, XSS, Path Traversal
        â€¢ 3 normal: /api/users, /search, /home
     â””â”€ Calls: add_rag_example(text, is_anomalous=bool, attack_type=str)
     â””â”€ Stores in: ChromaDB in-memory collection "soc_attacks"
     â””â”€ Run: python scripts/seed_rag.py


  OPTION 2: CSIC2010 Dataset (61,792 items)
  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  â””â”€ scripts/seed_rag_from_csic.py
     â””â”€ Source: Hugging Face Hub
        https://huggingface.co/datasets/nquangit/CSIC2010_dataset_classification
     â””â”€ Downloads: Real HTTP request payloads with classification labels
     â””â”€ Extracts columns: request (HTTP text) + label (normal/attack classification)
     â””â”€ Auto-detects: is_anomalous = (label != "normal")
     â””â”€ Stores: 61,792 items into ChromaDB
     â””â”€ Run: pip install datasets
          python scripts/seed_rag_from_csic.py


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âš ï¸  IMPORTANT: Currently NO dataset is pre-loaded!                          â”‚
â”‚                                                                              â”‚
â”‚    ChromaDB starts EMPTY. You must run seed_rag.py OR seed_rag_from_csic.pyâ”‚
â”‚    to populate it BEFORE using the system.                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


ğŸ”„ COMPLETE REQUEST FLOW (Using RAG)
================================================================================

User submits HTTP request(s)
        â†“
   [graph_app.py] Entry: soc_app.invoke({"requests": [...]})
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NODE 1: "decode"  (batch_decoder)                                       â”‚
â”‚  âœ“ Parse batch input â†’ split into individual requests                   â”‚
â”‚  Output: state["items"] = [{raw_request, ...}, ...]                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NODE 2: "rule"  (nodes_rule.py â†’ rule_engine)                          â”‚
â”‚  âœ“ Apply OWASP CRS patterns (80+ regex across 15 attack types)          â”‚
â”‚  âœ“ Calculate anomaly score, severity, attack_type                       â”‚
â”‚  âœ“ Set blocked=true if score â‰¥ threshold (5)                            â”‚
â”‚  Output: item["rule_score"], item["severity"], item["blocked"]           â”‚
â”‚          item["attack_type"], item["evidence"]                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NODE 3: "router"  (nodes_router.py)                                     â”‚
â”‚  âœ“ If blocked by rule â†’ set final_msg with "[BLOCKED] ..." message       â”‚
â”‚  Conditional decision: route_after_rule()                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                     â”‚                             â”‚
    â†“ (fast path)         â†“ (slow path)                 â”‚
  ALL BLOCKED?      NOT ALL BLOCKED?                   â”‚
    â”‚                     â”‚                             â”‚
    â”œâ”€â†’ cache_save â†â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                   â”‚
    â””â”€â†’ NODE 5a: "cache"  (nodes_cache.py) â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          âœ“ For NON-blocked items:
          
          CACHE HIT? â†’ Skip to llm_output restoration
          
          CACHE MISS? â†’ RAG VECTOR SEARCH:
          â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
          1. SentenceTransformer encodes request text
          2. Queries ChromaDB for top-3 similar items
          3. Returns: [
               {raw_request: "...", label: "anomalous/normal", attack_type: "..."},
               {raw_request: "...", label: "...", attack_type: "..."},
               {raw_request: "...", label: "...", attack_type: "..."}
             ]
          4. Formats as: "[ANOMALOUS] SQL Injection: ...\n[NORMAL] /api/users\n..."
          5. Stores in: item["rag_context"]
          â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
            â†“
    NODE 6: "llm"  (nodes_llm.py â†’ llm_backend.py)
    âœ“ Skip if: blocked OR cache_hit
    âœ“ Call Groq LLM with:
      - SYSTEM PROMPT: "You are SOC analyst. No guessing..."
      - USER MESSAGE: 
        HTTP REQUEST: {query}
        RELATED CONTEXT (RAG):
        {rag_context}
        Return verdict.
    âœ“ Get LLM analysis â†’ store in item["llm_output"]
            â†“
    NODE 7: "cache_save"  (nodes_cache_save.py)
    âœ“ For non-blocked items not yet cached:
      Save to cache: {
        "final_msg": ...,
        "llm_output": ...,
        "attack_type": ...,
        "severity": ...,
        "rule_score": ...,
        "evidence": ...
      }
    âœ“ Cache key: SHA256(request.lower())
    âœ“ At end of both paths (fast & slow join here)
            â†“
    NODE 8: "response"  (nodes_response.py)
    âœ“ Format output to rich JSON:
      {
        "label": "...",                 
        "attack_group": "...",          
        "attack_type": "...",           
        "confidence": 0.0-1.0,          
        "risk_score": 0-100,            
        "severity": "CRITICAL/ERROR/...",
        "evidence": "...",              
        "observed_patterns": [...],     
        "suggested_actions": [...],     
        "route": "fast"/"slow",         
        "event_type": "...",            
        "source": "rule_engine"/"llm_explainer",
        "explanation": "...",           
        "learning_note": "...",         
        "hallucination_suspected": bool,
        "generated_at": "ISO timestamp",
        "llm_model": "llama-3.3-70b-versatile"  (if from LLM)
      }
            â†“
         END


ğŸ“ FILE STRUCTURE & RESPONSIBILITIES
================================================================================

ROOT
â”œâ”€ graph_app.py
â”‚  â””â”€ Main StateGraph definition with 7 nodes and conditional routing
â”‚
â”œâ”€ soc_state.py
â”‚  â””â”€ SOCState TypedDict schema (all fields: requests, items, results)
â”‚
â”œâ”€ backends/
â”‚  â”œâ”€ rag_backend.py          â† WHERE RAG DATA LIVES
â”‚  â”‚  â”œâ”€ ChromaDB in-memory collection "soc_attacks"
â”‚  â”‚  â”œâ”€ add_rag_example(text, is_anomalous, attack_type)
â”‚  â”‚  â”œâ”€ vector_search(query) â†’ top-3 similar items
â”‚  â”‚  â””â”€ rag_list_parser(results) â†’ formatted string for LLM
â”‚  â”‚
â”‚  â”œâ”€ rule_engine.py          â† OWASP CRS PATTERNS
â”‚  â”‚  â”œâ”€ 15 attack types, 80+ patterns
â”‚  â”‚  â””â”€ analyze_request(text) â†’ score, severity, attack_type
â”‚  â”‚
â”‚  â”œâ”€ llm_backend.py          â† GROQ LLM
â”‚  â”‚  â”œâ”€ Requires: $GROQ_API_KEY environment variable
â”‚  â”‚  â””â”€ llm_analyze(query, rag_context) â†’ LLM verdict
â”‚  â”‚
â”‚  â”œâ”€ llm_backend_mock.py     â† MOCK LLM (no API key needed)
â”‚  â”‚  â””â”€ Simple heuristic for testing
â”‚  â”‚
â”‚  â”œâ”€ cache_backend.py        â† FAST LOOKUP
â”‚  â”‚  â”œâ”€ In-memory SHA256 hash cache
â”‚  â”‚  â””â”€ Prevents re-analysis of same requests
â”‚  â”‚
â”‚  â””â”€ batch_decoder.py        â† INPUT PARSING
â”‚
â”œâ”€ nodes/
â”‚  â”œâ”€ nodes_rule.py           â†’ Apply rule engine, detect attacks
â”‚  â”œâ”€ nodes_router.py         â†’ Route based on rule decision
â”‚  â”œâ”€ nodes_cache.py          â†’ Check cache / Load RAG context â† RAG VECTOR SEARCH HERE
â”‚  â”œâ”€ nodes_llm.py            â†’ Call LLM with RAG context
â”‚  â”œâ”€ nodes_cache_save.py     â†’ Save results to cache
â”‚  â””â”€ nodes_response.py       â†’ Format final JSON output
â”‚
â”œâ”€ builders/
â”‚  â”œâ”€ response_builder.py     â†’ Rich JSON formatter
â”‚  â””â”€ audit_logger.py         â†’ Event logging
â”‚
â”œâ”€ scripts/
â”‚  â”œâ”€ seed_rag.py              â† RAG DATASET OPTION 1 (manual, 6 items)
â”‚  â”‚  â””â”€ Run: python scripts/seed_rag.py
â”‚  â”‚
â”‚  â”œâ”€ seed_rag_from_csic.py    â† RAG DATASET OPTION 2 (CSIC2010, 61k items)
â”‚  â”‚  â””â”€ Run: python scripts/seed_rag_from_csic.py
â”‚  â”‚
â”‚  â”œâ”€ inspect_chromadb.py      â† View what's in RAG
â”‚  â”‚  â””â”€ Run: python scripts/inspect_chromadb.py
â”‚  â”‚
â”‚  â””â”€ seed_and_inspect.py      â† Seed + view in one go
â”‚     â””â”€ Run: python scripts/seed_and_inspect.py
â”‚
â”œâ”€ tests/
â”‚  â”œâ”€ test_cache_flow.py       â† Test cache hit/miss behavior (4 tests)
â”‚  â””â”€ test_cache_mock.py       â† Test without API key (mock LLM)
â”‚
â”œâ”€ docs/
â”‚  â”œâ”€ README.md
â”‚  â”œâ”€ FAST_SLOW_PATH_DOCS.md
â”‚  â”œâ”€ RESPONSE_FORMAT_DOC.md
â”‚  â””â”€ ... (other documentation)
â”‚
â””â”€ venv_langgraph/            â†’ Python virtual environment


ğŸ”‘ KEY DECISION POINTS
================================================================================

Decision 1: DATASET SOURCE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  â”Œâ”€ Small dataset (quick test)?
  â”‚  â””â”€ Run: python scripts/seed_rag.py
  â”‚     â””â”€ 6 hard-coded examples loaded instantly
  â”‚
  â””â”€ Large dataset (production)?
     â””â”€ Run: python scripts/seed_rag_from_csic.py
        â””â”€ Downloads 61,792 real HTTP payloads from Hugging Face
           â””â”€ Takes ~2-5 minutes first time
           â””â”€ Better RAG quality: LLM sees real attack patterns


Decision 2: REQUEST CLASSIFICATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  â”Œâ”€ Rule engine says BLOCKED?
  â”‚  â””â”€ Fast path: Skip LLM, save to cache, return result
  â”‚     â””â”€ Time: <100ms
  â”‚
  â””â”€ Rule engine says NOT BLOCKED?
     â””â”€ Slow path:
        â”œâ”€ Check cache: Found?
        â”‚  â””â”€ Restore from cache, skip LLM
        â”‚
        â””â”€ Not in cache?
           â”œâ”€ RAG vector search: Find 3 similar historical requests
           â”œâ”€ Pass RAG context to Groq LLM
           â”œâ”€ LLM analyzes with context
           â””â”€ Save result to cache for next time
           â””â”€ Time: ~1-2 seconds (depends on Groq API)


ğŸ“ˆ PERFORMANCE CHARACTERISTICS
================================================================================

Fast Path (Rule-blocked):
  Rule check â†’ cache save â†’ response = ~50ms
  
Cached Hit (Same request seen before):
  Cache lookup â†’ skip LLM â†’ response = ~100-200ms
  
Cache Miss (New request):
  RAG search (SentenceTransformer embedding): ~200-300ms
  LLM call (Groq API):  ~800-1500ms
  Save to cache: ~10ms
  Total: ~1-2 seconds

Without RAG (if empty ChromaDB):
  LLM called with no context
  LLM might over-analyze or hallucinate
  RESULT: Lower quality classification


âœ… QUICK START (RECOMMENDED)
================================================================================

Step 1: Ensure dependencies
  cd "e:\DO AN MOI NHAT\LangChain"
  source venv_langgraph/Scripts/activate

Step 2: Seed RAG (choose one):
  python scripts/seed_rag.py              # Quick test (6 items)
         OR
  python scripts/seed_rag_from_csic.py    # Production (61k items)

Step 3: Verify RAG data
  python scripts/inspect_chromadb.py

Step 4: Run tests
  python tests/test_cache_flow.py         # Uses Groq API (needs GROQ_API_KEY)
         OR
  python tests/test_cache_mock.py         # Uses mock LLM (no API key needed)

Step 5: Start API server
  python api.py
  Then: curl -X POST http://127.0.0.1:8000/analyze -d '{"requests": [...]}'

================================================================================
